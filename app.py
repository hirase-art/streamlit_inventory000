import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib
import matplotlib.gridspec as gridspec

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(layout="wide", page_title="åœ¨åº«ãƒ»å‡ºè·å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ")

# --------------------------------------------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿å–å¾— (Supabase)
# --------------------------------------------------------------------------
conn = st.connection("postgresql", type="sql")

@st.cache_data(ttl=600)
def load_supabase(table_name):
    try:
        query = f'SELECT * FROM "{table_name}";'
        df = conn.query(query)
        # IDåˆ—ãªã©ã¯æ–‡å­—åˆ—ã¨ã—ã¦å®‰å…¨ã«æ‰±ã†
        str_cols = ['å•†å“ID', 'æ¥­å‹™åŒºåˆ†ID', 'å€‰åº«ID', 'SET_ID', 'month_code', 'week_code']
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip().replace(['nan', 'None', ''], np.nan)
        return df
    except:
        return pd.DataFrame()

with st.spinner('æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸä¸­...'):
    df_inv = load_supabase("åœ¨åº«æƒ…å ±")
    df_ship_m = load_supabase("T_9x30")
    df_ship_w = load_supabase("T_9x07")
    df_pack = load_supabase("Pack_Classification")
    df_set = load_supabase("SET_Class")

# --------------------------------------------------------------------------
# 2. è£œåŠ©é–¢æ•° (ãƒ©ãƒ™ãƒ«è¿½åŠ )
# --------------------------------------------------------------------------
def add_labels_to_stacked_bar(ax, data_df):
    bottom = pd.Series([0.0] * len(data_df), index=data_df.index)
    for col in data_df.columns:
        values = data_df[col].fillna(0)
        y_pos = bottom + values / 2
        for i, val in enumerate(values):
            if val > (data_df.sum(axis=1).max() * 0.05):
                ax.text(i, y_pos.iloc[i], f'{int(val)}', ha='center', va='center', fontsize=6, color='white', fontweight='bold')
        bottom += values

# --------------------------------------------------------------------------
# 3. å…±é€šãƒ•ã‚£ãƒ«ã‚¿ãƒ­ã‚¸ãƒƒã‚¯ (ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾¹åº•ã‚¬ãƒ¼ãƒ‰ç‰ˆ)
# --------------------------------------------------------------------------
def apply_filters(df, master, s_id, s_name, dai, chu, sho):
    if df.empty: return df
    
    # ãƒã‚¹ã‚¿çµåˆ (suffixesã‚’æ˜ç¤ºã—ã¦åˆ—åã®è¡çªã‚’ç®¡ç†)
    m_sub = master[[c for c in ['å•†å“ID', 'å¤§åˆ†é¡', 'ä¸­åˆ†é¡', 'å°åˆ†é¡', 'å•†å“å'] if c in master.columns]].drop_duplicates(subset='å•†å“ID')
    res = pd.merge(df, m_sub, on='å•†å“ID', how='left', suffixes=('', '_master'))
    
    # åˆ†é¡æƒ…å ±ã®å®‰å…¨ãªè£œå®Œ
    for col in ['å¤§åˆ†é¡', 'ä¸­åˆ†é¡', 'å°åˆ†é¡']:
        if col in res.columns:
            res[col] = res[col].fillna("(æœªç™»éŒ²)")
    
    # å•†å“åã®è£œå®Œ (KeyErrorå¯¾ç­–)
    if 'å•†å“å' not in res.columns:
        if 'å•†å“å_master' in res.columns:
            res = res.rename(columns={'å•†å“å_master': 'å•†å“å'})
        else:
            res['å•†å“å'] = "(åç§°ä¸æ˜)"
    else:
        if 'å•†å“å_master' in res.columns:
            res['å•†å“å'] = res['å•†å“å'].fillna(res['å•†å“å_master'])
        res['å•†å“å'] = res['å•†å“å'].fillna("(åç§°ä¸æ˜)")

    # å•†å“IDæ¤œç´¢ (è¤‡æ•°æ¡æ•°ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ)
    if s_id:
        raw_ids = [i.strip() for i in s_id.split(',') if i.strip()]
        target_ids = set(raw_ids)
        for rid in raw_ids:
            if rid.isdigit():
                for length in range(1, 10): target_ids.add(rid.zfill(length))
        res = res[res['å•†å“ID'].isin(list(target_ids))]
            
    if s_name: 
        res = res[res['å•†å“å'].str.contains(s_name, na=False)]
    
    if dai: res = res[res['å¤§åˆ†é¡'].isin(dai)]
    if chu: res = res[res['ä¸­åˆ†é¡'].isin(chu)]
    if sho: res = res[res['å°åˆ†é¡'].isin(sho)]
    return res

# --------------------------------------------------------------------------
# 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼
# --------------------------------------------------------------------------
st.sidebar.header("ğŸ” å…±é€šæ¤œç´¢")
search_id = st.sidebar.text_input("å•†å“IDæ¤œç´¢ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šå¯):", placeholder="2039, 2040")
search_name = st.sidebar.text_input("å•†å“åæ¤œç´¢ (ã‚ã„ã¾ã„):")

st.sidebar.markdown("---")
st.sidebar.header(":blue[ğŸšš å‡ºè·ãƒ•ã‚£ãƒ«ã‚¿]")
ship_type = st.sidebar.radio("å‡ºè·ç¨®åˆ¥:", ["å…¨ã¦", "å¸å‡ºè· (4)", "é€šè²©å‡ºè· (7)"], horizontal=True)
unit = st.sidebar.radio("é›†è¨ˆå˜ä½:", ["Pack", "SET"], horizontal=True)
df_m_source = df_pack if unit == "Pack" else df_set.rename(columns={'SET_ID': 'å•†å“ID', 'ã‚»ãƒƒãƒˆæ§‹æˆåç§°': 'å•†å“å'})

agg_level = st.sidebar.radio("é›†è¨ˆç²’åº¦:", ["å¤§åˆ†é¡", "ä¸­åˆ†é¡", "å°åˆ†é¡", "å•†å“ID"], index=3, horizontal=True)
show_total = st.sidebar.radio("åˆè¨ˆè¡¨ç¤º:", ["ãªã—", "ã‚ã‚Š"], horizontal=True)
num_months = st.sidebar.slider("æœˆé–“è¡¨ç¤ºæœŸé–“", 3, 26, 12)
num_weeks = st.sidebar.slider("é€±é–“è¡¨ç¤ºæœŸé–“", 3, 20, 12)

sel_dai = st.sidebar.multiselect("å¤§åˆ†é¡:", options=sorted(df_m_source['å¤§åˆ†é¡'].dropna().unique()) if not df_m_source.empty else [])
chu_opts = sorted(df_m_source[df_m_source['å¤§åˆ†é¡'].isin(sel_dai)]['ä¸­åˆ†é¡'].dropna().unique()) if sel_dai else []
sel_chu = st.sidebar.multiselect("ä¸­åˆ†é¡:", options=chu_opts)
sho_opts = sorted(df_m_source[df_m_source['ä¸­åˆ†é¡'].isin(sel_chu)]['å°åˆ†é¡'].dropna().unique()) if sel_chu else []
sel_sho = st.sidebar.multiselect("å°åˆ†é¡:", options=sho_opts)

# --------------------------------------------------------------------------
# 5. ãƒ¡ã‚¤ãƒ³è¡¨ç¤º
# --------------------------------------------------------------------------
tab_ship, tab_inv = st.tabs(["ğŸ“ å‡ºè·åˆ†æ", "ğŸ“Š åœ¨åº«åˆ†æ"])

with tab_ship:
    st.header(f"ğŸšš å‡ºè·å®Ÿç¸¾åˆ†æ ({ship_type})")
    
    def get_ship_pivot(target_df, code_col, period):
        if target_df.empty: return pd.DataFrame()
        f_df = apply_filters(target_df, df_m_source, search_id, search_name, sel_dai, sel_chu, sel_sho)
        if ship_type == "å¸å‡ºè· (4)": f_df = f_df[f_df['æ¥­å‹™åŒºåˆ†ID'] == '4']
        elif ship_type == "é€šè²©å‡ºè· (7)": f_df = f_df[f_df['æ¥­å‹™åŒºåˆ†ID'] == '7']
        if f_df.empty: return pd.DataFrame()
        
        idx_cols = ["å¤§åˆ†é¡", "ä¸­åˆ†é¡", "å°åˆ†é¡", "å•†å“ID", "å•†å“å"]
        current_idx = idx_cols[:idx_cols.index(agg_level if agg_level != "å•†å“ID" else "å•†å“ID") + 1]
        if agg_level == "å•†å“ID": current_idx = ["å¤§åˆ†é¡", "ä¸­åˆ†é¡", "å°åˆ†é¡", "å•†å“ID", "å•†å“å"]
        
        try:
            piv = f_df.pivot_table(index=current_idx, columns=code_col, values='åˆè¨ˆå‡ºè·æ•°', aggfunc='sum', dropna=False).fillna(0)
            piv = piv.iloc[:, -period:]
            if show_total == "ã‚ã‚Š": piv['åˆè¨ˆ'] = piv.sum(axis=1)
            return piv
        except: return pd.DataFrame()

    st.subheader("ğŸ—“ï¸ æœˆé–“æ¨ç§»")
    p_m = get_ship_pivot(df_ship_m, 'month_code', num_months)
    if not p_m.empty: st.dataframe(p_m, use_container_width=True)
    else: st.info("è¡¨ç¤ºã§ãã‚‹æœˆé–“å‡ºè·ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.subheader("ğŸ—“ï¸ é€±é–“æ¨ç§»")
    p_w = get_ship_pivot(df_ship_w, 'week_code', num_weeks)
    if not p_w.empty: st.dataframe(p_w, use_container_width=True)
    else: st.info("è¡¨ç¤ºã§ãã‚‹é€±é–“å‡ºè·ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab_inv:
    st.header("ğŸ“¦ åœ¨åº«è©³ç´°åˆ†æ")
    inv_f = apply_filters(df_inv, df_pack, search_id, search_name, sel_dai, sel_chu, sel_sho)
    inv_f['æœ‰åŠ¹åœ¨åº«'] = pd.to_numeric(inv_f['åœ¨åº«æ•°(å¼•å½“æ•°ã‚’å«ã‚€)'], errors='coerce').fillna(0) - pd.to_numeric(inv_f['å¼•å½“æ•°'], errors='coerce').fillna(0)
    
    st.dataframe(inv_f[['å€‰åº«å', 'å•†å“ID', 'å•†å“å', 'æœ‰åŠ¹åœ¨åº«', 'å“è³ªåŒºåˆ†å', 'å¤§åˆ†é¡']], use_container_width=True)
