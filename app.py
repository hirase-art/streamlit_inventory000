import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(layout="wide", page_title="åœ¨åº«ãƒ»å‡ºè·åˆ†æã‚·ã‚¹ãƒ†ãƒ  Pro")

# --- 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š ---
conn = st.connection("postgresql", type="sql")

def clean_column_names(df):
    df.columns = df.columns.str.strip().str.replace('"', '').str.replace(' ', '')
    if 'å•†å“ID' in df.columns:
        df = df.dropna(subset=['å•†å“ID'])
        df['å•†å“ID'] = df['å•†å“ID'].astype(str).str.replace(r'\.0$', '', regex=True).str.lstrip('0')
    return df

@st.cache_data(ttl=600)
def load_all_masters():
    """Packã¨SETã‚’çµ±åˆã—ã¦ä¸€ã¤ã®ãƒã‚¹ã‚¿ã¨ã—ã¦æ‰±ã†"""
    p = clean_column_names(conn.query('SELECT * FROM "Pack_Classification";'))
    s = clean_column_names(conn.query('SELECT * FROM "SET_Class";'))
    
    # SETãƒã‚¹ã‚¿ã®åˆ—åæ•´ç†
    s = s.rename(columns={'SETID': 'å•†å“ID', 'SET_ID': 'å•†å“ID', 'ã‚»ãƒƒãƒˆæ§‹æˆåç§°': 'å•†å“å'})
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒãªã„å ´åˆã®åˆæœŸå€¤
    for col in ['å¤§åˆ†é¡', 'ä¸­åˆ†é¡', 'å°åˆ†é¡']:
        if col not in p.columns: p[col] = "-"
        if col not in s.columns: s[col] = "SETå•†å“" if col == 'ä¸­åˆ†é¡' else ("SET" if col == 'å¤§åˆ†é¡' else "-")
    
    cols = ['å¤§åˆ†é¡', 'ä¸­åˆ†é¡', 'å°åˆ†é¡', 'å•†å“ID', 'å•†å“å']
    combined = pd.concat([p[cols], s[cols]], ignore_index=True).drop_duplicates(subset=['å•†å“ID'])
    return combined

@st.cache_data(ttl=300)
def get_shipment_summary(period_type="monthly"):
    table = "shipment_monthly" if period_type == "monthly" else "shipment_weekly"
    df = conn.query(f'SELECT * FROM "{table}";')
    return clean_column_names(df)

@st.cache_data(ttl=300)
def get_incoming_summary():
    # å…¥è·äºˆå®š T_4001
    query = 'SELECT "å•†å“ID", SUM("äºˆå®šæ•°") as "å…¥è·äºˆå®šåˆè¨ˆ", MIN(to_date("å…¥è·äºˆå®šæ—¥"::text, \'YYYYMMDD\')) as "æ¬¡å›å…¥è·æ—¥" FROM "T_4001" GROUP BY 1'
    df = conn.query(query)
    return clean_column_names(df)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸä¸­...'):
    df_m_ship_raw = get_shipment_summary("monthly")
    df_w_ship_raw = get_shipment_summary("weekly")
    df_incoming = get_incoming_summary()
    df_master = load_all_masters()
    
    # åœ¨åº«é›†ç´„
    df_inv_raw = clean_column_names(conn.query('SELECT * FROM "åœ¨åº«æƒ…å ±";'))
    df_inv_raw.columns = ['åœ¨åº«æ—¥', 'å€‰åº«ID', 'å€‰åº«å', 'ãƒ–ãƒ­ãƒƒã‚¯ID', 'ãƒ–ãƒ­ãƒƒã‚¯å', 'ãƒ­ã‚±', 'å•†å“ID', 'ãƒãƒ¼ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'ãƒ­ãƒƒãƒˆ', 'æœ‰åŠ¹æœŸé™', 'å“è³ªåŒºåˆ†ID', 'å“è³ªåŒºåˆ†å', 'åœ¨åº«æ•°å¼•å½“å«', 'å¼•å½“æ•°'] + [f"col_{i}" for i in range(len(df_inv_raw.columns) - 15)]
    df_inv_raw['åˆ©ç”¨å¯èƒ½'] = pd.to_numeric(df_inv_raw['åœ¨åº«æ•°å¼•å½“å«'], errors='coerce').fillna(0) - pd.to_numeric(df_inv_raw['å¼•å½“æ•°'], errors='coerce').fillna(0)
    df_inv_final = df_inv_raw[df_inv_raw['å“è³ªåŒºåˆ†ID'].astype(str).isin(['1', '2'])].pivot_table(index='å•†å“ID', columns='å€‰åº«ID', values='åˆ©ç”¨å¯èƒ½', aggfunc='sum').fillna(0).rename(columns={'7': 'å¤§é˜ª', '8': 'åƒè‘‰', 7: 'å¤§é˜ª', 8: 'åƒè‘‰'}).reset_index()
    for c in ['å¤§é˜ª', 'åƒè‘‰']:
        if c not in df_inv_final.columns: df_inv_final[c] = 0
    df_inv_final['ç¾åœ¨åº«åˆè¨ˆ'] = df_inv_final['å¤§é˜ª'] + df_inv_final['åƒè‘‰']

# --- 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ•ã‚£ãƒ«ã‚¿ãƒ»æ¤œç´¢ ---
st.sidebar.header("ğŸ” çµã‚Šè¾¼ã¿æ¡ä»¶")

# å€‰åº«ãƒ•ã‚£ãƒ«ã‚¿
sel_wh = st.sidebar.selectbox("å‡ºè·å…ƒå€‰åº«:", ["å…¨ç¤¾", "7 (å¤§é˜ª)", "8 (åƒè‘‰)"])

# è¤‡æ•°é¸æŠãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆéšå±¤ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
def multi_select_filter(df, col, label):
    options = sorted(df[col].dropna().unique().tolist())
    selected = st.sidebar.multiselect(label, options)
    return df[df[col].isin(selected)] if selected else df

df_f = df_master.copy()
df_f = multi_select_filter(df_f, 'å¤§åˆ†é¡', "å¤§åˆ†é¡ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰")
df_f = multi_select_filter(df_f, 'ä¸­åˆ†é¡', "ä¸­åˆ†é¡ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰")
df_f = multi_select_filter(df_f, 'å°åˆ†é¡', "å°åˆ†é¡ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰")

# åˆ¤å®šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
all_status = ["âš ï¸é–“ã«åˆã‚ãªã„", "è¦ç™ºæ³¨", "å…¥è·å¾…ã¡", "å®‰å…¨", "ğŸ“ˆéå¤š", "å‹•å‘ãªã—"]
status_filter = st.sidebar.multiselect("åˆ¤å®šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:", all_status, default=all_status)

st.sidebar.markdown("---")
# ã€å¾©æ´»ã€‘ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢çª“
search_id = st.sidebar.text_input("å•†å“IDæ¤œç´¢ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šå¯):", help="ä¾‹: 10001, 10002")
search_name = st.sidebar.text_input("å•†å“åã‚ã„ã¾ã„æ¤œç´¢:")

st.sidebar.markdown("---")
# äºˆæ¸¬æœŸé–“è¨­å®š
avg_n_month = st.sidebar.slider("æœˆæ¬¡äºˆæ¸¬å¹³å‡ (nãƒ¶æœˆ):", 1, 12, 3)
avg_n_week = st.sidebar.slider("é€±æ¬¡äºˆæ¸¬å¹³å‡ (né€±):", 1, 12, 4)

# --- 3. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ ---
def analyze_stock(df_ship_raw, master, inv, incoming, avg_n, period_label):
    df_ship = df_ship_raw.copy()
    if sel_wh != "å…¨ç¤¾":
        df_ship = df_ship[df_ship['å€‰åº«ID'] == sel_wh.split(" ")[0]]
    
    # å®Ÿç¸¾ãƒ”ãƒœãƒƒãƒˆ (æ–°â†’æ—§)
    piv = df_ship.pivot_table(index="å•†å“ID", columns='code', values='å‡ºè·æ•°', aggfunc='sum').fillna(0)
    piv_cols_desc = sorted(piv.columns, reverse=True)
    piv = piv[piv_cols_desc]

    # ãƒ‡ãƒ¼ã‚¿çµåˆ
    res = pd.merge(master, inv[['å•†å“ID', 'åƒè‘‰', 'å¤§é˜ª', 'ç¾åœ¨åº«åˆè¨ˆ']], on='å•†å“ID', how='inner')
    res = pd.merge(res, incoming[['å•†å“ID', 'å…¥è·äºˆå®šåˆè¨ˆ', 'æ¬¡å›å…¥è·æ—¥']], on='å•†å“ID', how='left')
    res = pd.merge(res, piv, on='å•†å“ID', how='left').fillna(0)

    # å……è¶³è¨ˆç®—
    res['å¹³å‡å‡ºè·'] = res[piv_cols_desc[:avg_n]].mean(axis=1).round(1)
    res['ç¾å……è¶³'] = np.where(res['å¹³å‡å‡ºè·'] > 0, (res['ç¾åœ¨åº«åˆè¨ˆ'] / res['å¹³å‡å‡ºè·']).round(1), np.inf)
    res['å°†å……è¶³'] = np.where(res['å¹³å‡å‡ºè·'] > 0, ((res['ç¾åœ¨åº«åˆè¨ˆ'] + res['å…¥è·äºˆå®šåˆè¨ˆ'].fillna(0)) / res['å¹³å‡å‡ºè·']).round(1), np.inf)
    
    # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
    days_per = 30 if period_label == "ãƒ¶æœˆ" else 7
    res['åœ¨åº«çµ‚äº†æ—¥æ•°'] = np.where(res['å¹³å‡å‡ºè·'] > 0, (res['ç¾åœ¨åº«åˆè¨ˆ'] / (res['å¹³å‡å‡ºè·'] / days_per)), 999)
    res['å…¥è·å¾…ã¡æ—¥æ•°'] = (pd.to_datetime(res['æ¬¡å›å…¥è·æ—¥']) - datetime.now()).dt.days.fillna(0)

    def get_status(row):
        if row['å¹³å‡å‡ºè·'] == 0 and row['ç¾åœ¨åº«åˆè¨ˆ'] == 0: return "å‹•å‘ãªã—"
        if row['ç¾å……è¶³'] >= 3.0: return "ğŸ“ˆéå¤š"
        if row['ç¾å……è¶³'] >= 1.0: return "å®‰å…¨"
        if row['å…¥è·äºˆå®šåˆè¨ˆ'] == 0: return "è¦ç™ºæ³¨"
        if row['åœ¨åº«çµ‚äº†æ—¥æ•°'] < row['å…¥è·å¾…ã¡æ—¥æ•°']: return "âš ï¸é–“ã«åˆã‚ãªã„"
        return "å…¥è·å¾…ã¡"

    res['åˆ¤å®š'] = res.apply(get_status, axis=1)
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚°ãƒ©ãƒ•ç”¨ (æ—§â†’æ–°)
    chart_cols = piv_cols_desc[:12][::-1]
    res['ãƒˆãƒ¬ãƒ³ãƒ‰'] = res[chart_cols].values.tolist()

    # --- æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ ---
    if status_filter: res = res[res['åˆ¤å®š'].isin(status_filter)]
    if search_id: 
        ids = [i.strip().lstrip('0') for i in search_id.split(',')]
        res = res[res['å•†å“ID'].isin(ids)]
    if search_name: 
        res = res[res['å•†å“å'].str.contains(search_name, na=False)]

    # ã‚«ãƒ©ãƒ ä¸¦ã³æ›¿ãˆï¼ˆå…¥è·äºˆå®šåˆè¨ˆã‚’ä¸­å¤®ã«é…ç½®ï¼‰
    display_cols = [
        "åˆ¤å®š", "å¤§åˆ†é¡", "ä¸­åˆ†é¡", "å°åˆ†é¡", "å•†å“ID", "å•†å“å", 
        "ç¾åœ¨åº«åˆè¨ˆ", "å…¥è·äºˆå®šåˆè¨ˆ", "ç¾å……è¶³", "å°†å……è¶³", "ãƒˆãƒ¬ãƒ³ãƒ‰"
    ] + piv_cols_desc[:12]
    
    st.subheader(f"ğŸ“Š {period_label}æ¬¡åˆ†æ (äºˆæ¸¬æœŸé–“: {avg_n}{period_label})")
    st.dataframe(
        res[display_cols],
        use_container_width=True, hide_index=True,
        column_config={
            "ãƒˆãƒ¬ãƒ³ãƒ‰": st.column_config.AreaChartColumn("æ¨ç§»(æ—§â†’æ–°)", y_min=0),
            "ç¾å……è¶³": st.column_config.ProgressColumn("ç¾å……è¶³", min_value=0, max_value=3, format="%.1f"),
            "å°†å……è¶³": st.column_config.ProgressColumn("å°†å……è¶³", min_value=0, max_value=3, format="%.1f"),
            "å…¥è·äºˆå®šåˆè¨ˆ": st.column_config.NumberColumn("å…¥è·äºˆå®š", format="%d")
        }
    )

# --- 4. ãƒ¡ã‚¤ãƒ³è¡¨ç¤º ---
tab1, tab2 = st.tabs(["ğŸš€ åœ¨åº«é©æ­£åŒ–åˆ†æ", "ğŸ“¦ æ‹ ç‚¹åˆ¥åœ¨åº«è©³ç´°"])
with tab1:
    analyze_stock(df_m_ship_raw, df_f, df_inv_final, df_incoming, avg_n_month, "ãƒ¶æœˆ")
    st.write("---")
    analyze_stock(df_w_ship_raw, df_f, df_inv_final, df_incoming, avg_n_week, "é€±")

with tab2:
    # æ‹ ç‚¹åˆ¥è©³ç´°ã‚‚ãƒã‚¹ã‚¿çµ±åˆç‰ˆã‚’è¡¨ç¤º
    st.dataframe(pd.merge(df_f, df_inv_final, on='å•†å“ID', how='inner'), use_container_width=True)
