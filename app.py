import streamlit as st
import pandas as pd
import logging
import glob
import matplotlib.pyplot as plt
import japanize_matplotlib
import numpy as np
import matplotlib.gridspec as gridspec

# ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šè¨­å®šãŒèª­ã¿è¾¼ã‚ã¦ã„ã‚‹ã‹ç”»é¢ã«å‡ºã™
# æˆåŠŸã™ã‚Œã°ã€ã“ã“ã«DBæƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
if st.secrets:
    st.write("âœ… è¨­å®šã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸ")
else:
    st.write("âŒ è¨­å®šï¼ˆsecretsï¼‰ãŒç©ºã§ã™")

# --- ãƒ­ã‚°è¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='app.log',
    filemode='w'
)

# --------------------------------------------------------------------------
# 1. Supabase æ¥ç¶šç¢ºç«‹
# --------------------------------------------------------------------------
try:
    # secrets.toml ã® [connections.postgresql] ã‚’æ¢ã—ã«è¡Œãã¾ã™
    conn = st.connection("postgresql", type="sql")
except Exception as e:
    st.error(f"æ¥ç¶šè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")

# --------------------------------------------------------------------------
# 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°
# --------------------------------------------------------------------------

@st.cache_data(ttl=3600)
def load_data_from_supabase(table_name):
    """Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€IDåˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹"""
    try:
        query = f'SELECT * FROM "{table_name}";'
        df = conn.query(query)
        
        # IDé–¢é€£ã®åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆCSVèª­ã¿è¾¼ã¿æ™‚ã®æŒ™å‹•ã‚’å†ç¾ï¼‰
        str_cols = ['å•†å“ID', 'å€‰åº«ID', 'æ¥­å‹™åŒºåˆ†ID', 'SET_ID']
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).replace('None', np.nan).replace('nan', np.nan)
        return df
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã®å–å¾—å¤±æ•—: {e}")
        return pd.DataFrame()

@st.cache_data
def load_single_csv(path, encoding='utf-8'):
    """æ—¢å­˜ã®CSVèª­ã¿è¾¼ã¿ï¼ˆãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰"""
    try:
        return pd.read_csv(path, encoding=encoding, dtype={'å•†å“ID': str, 'å€‰åº«ID': str, 'æ¥­å‹™åŒºåˆ†ID': str, 'SET_ID': str})
    except:
        return None

# è£œåŠ©é–¢æ•°ï¼šæ£’ã‚°ãƒ©ãƒ•ã«ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
def add_labels_to_stacked_bar(ax, data_df):
    # (æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ç¶­æŒ)
    bottom = pd.Series([0.0] * len(data_df), index=data_df.index)
    for col in data_df.columns:
        values = data_df[col]
        y_pos = bottom + values / 2
        for i, val in enumerate(values):
            if val > 0:
                ax.text(i, y_pos.iloc[i], f'{int(val)}', ha='center', va='center', fontsize=5, color='white')
        bottom += values

@st.cache_data
def convert_df(df):
    return df.to_csv(encoding='utf-8-sig').encode('utf-8-sig')

# --------------------------------------------------------------------------
# 3. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# --------------------------------------------------------------------------
def main():
    st.set_page_config(layout="wide")
    st.title('ğŸ“Š åœ¨åº«ãƒ»å‡ºè·ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚¢ãƒ—ãƒª')

    # --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    # ãƒã‚¹ã‚¿é¡ã¯ã¾ã CSVã®ã¾ã¾ï¼ˆé †æ¬¡Supabaseã¸ç§»è¡Œå¯èƒ½ï¼‰
    df1 = load_single_csv("T_9x30.csv", encoding='utf-8')
    df_pack_master = load_single_csv("PACK_Classification.csv", encoding='utf-8')
    df_set_master = load_single_csv("SET_Class.csv", encoding='utf-8')
    
    # â˜… ã“ã“ãŒé‡è¦ï¼GitHubã®CSVã§ã¯ãªãã€Supabaseã‹ã‚‰èª­ã¿è¾¼ã‚€
    with st.spinner('Supabaseã‹ã‚‰åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...'):
        df3 = load_data_from_supabase("åœ¨åº«æƒ…å ±")
        df5 = load_data_from_supabase("T_9x07")

    # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã®ãƒã‚§ãƒƒã‚¯
    if df3.empty:
        st.error("åœ¨åº«ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Supabaseã®ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ä»¥é™ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ã‚°ãƒ©ãƒ•æç”»ãƒ­ã‚¸ãƒƒã‚¯ ---
    # (ä»¥å‰ã® app.py ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«ç¶šã‘ã‚‹)
    st.success("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
    st.subheader("åœ¨åº«æƒ…å ±ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df3.head())

if __name__ == "__main__":
    main()
