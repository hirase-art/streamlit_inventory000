import streamlit as st
import pandas as pd
import logging
import glob
import matplotlib.pyplot as plt
import japanize_matplotlib
import numpy as np
import matplotlib.gridspec as gridspec

# --- ãƒ­ã‚°è¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='app.log',
    filemode='w'
)

st.title('ğŸ“Š åœ¨åº«ãƒ»å‡ºè·ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚¢ãƒ—ãƒª')

# --------------------------------------------------------------------------
# 1. Supabase æ¥ç¶šè¨­å®š
# --------------------------------------------------------------------------
# ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šsecretsãŒèª­ã¿è¾¼ã‚ã¦ã„ã‚‹ã‹ç¢ºèª
if not st.secrets:
    st.warning("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'.streamlit/secrets.toml' ã¾ãŸã¯ Streamlit Cloud ã® 'Secrets' è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

try:
    # st.connection ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š
    conn = st.connection("postgresql", type="sql")
except Exception as e:
    st.error(f"Supabaseã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --------------------------------------------------------------------------
# 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°
# --------------------------------------------------------------------------

# â˜… æ–°è¦è¿½åŠ : Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
@st.cache_data(ttl=3600)
def load_data_from_supabase(table_name):
    """Supabaseã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€å‹å¤‰æ›ã‚’è¡Œã†é–¢æ•°"""
    logging.info(f"Supabase: {table_name} ã‹ã‚‰ã®èª­ã¿è¾¼ã¿é–‹å§‹ã€‚")
    try:
        query = f'SELECT * FROM "{table_name}";'
        df = conn.query(query)
        
        # IDé–¢é€£ã®åˆ—ã‚’æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã‚€ã‚ˆã†ã«æŒ‡å®š (CSVèª­ã¿è¾¼ã¿æ™‚ã®ä»•æ§˜ã‚’ç¶™æ‰¿)
        str_cols = ['å•†å“ID', 'å€‰åº«ID', 'æ¥­å‹™åŒºåˆ†ID', 'SET_ID']
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).replace('None', np.nan).replace('nan', np.nan)
        
        logging.info(f"Supabase: {table_name} ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return df
    except Exception as e:
        logging.error(f"Supabaseã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return pd.DataFrame()

@st.cache_data
def load_single_csv(path, encoding='utf-8'):
    """æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‹ã‚‰å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°"""
    # (æ—¢å­˜ã®é–¢æ•°ã‚’ç¶­æŒ)
    try:
        df = pd.read_csv(path, encoding=encoding, dtype={'å•†å“ID': str, 'å€‰åº«ID': str, 'æ¥­å‹™åŒºåˆ†ID': str, 'SET_ID': str})
        return df
    except Exception as e:
        return None

# (add_labels_to_stacked_bar ãªã©ã®è£œåŠ©é–¢æ•°ã¯çœç•¥ã›ãšã«ç¶­æŒã—ã¦ãã ã•ã„)

try:
    # --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    # ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã¾ã CSVã‹ã‚‰èª­ã¿è¾¼ã‚€æ§‹æˆã‚’ç¶­æŒï¼ˆå¿…è¦ã«å¿œã˜ã¦é †æ¬¡Supabaseã¸ç§»è¡Œå¯èƒ½ï¼‰
    df1 = load_single_csv("T_9x30.csv", encoding='utf-8')
    df_pack_master = load_single_csv("PACK_Classification.csv", encoding='utf-8') 
    df_set_master = load_single_csv("SET_Class.csv", encoding='utf-8') 
    
    # â˜… æ”¹ä¿®ãƒã‚¤ãƒ³ãƒˆ: GitHubä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ãªãã€Supabaseã‹ã‚‰èª­ã¿è¾¼ã‚€
    # ä»Šå¾Œã¯ git push ã›ãšã«ã€Google Driveã«ç½®ãã ã‘ã§æ›´æ–°ã•ã‚Œã¾ã™
    df3 = load_data_from_supabase("åœ¨åº«æƒ…å ±") 
    
    # T_9x07 ã‚‚ã™ã§ã«Supabaseã«åŒæœŸã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã¡ã‚‰ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™
    df5 = load_data_from_supabase("T_9x07")

    # (ä»¥é™ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ã‚°ãƒ©ãƒ•æç”»ãƒ­ã‚¸ãƒƒã‚¯ã¯ä¸€åˆ‡å¤‰æ›´ãªã—ã§å‹•ãã¾ã™)
